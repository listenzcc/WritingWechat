# 扩散模型入门（七）

本文将对前文内容进行总结，最终列出扩散模型的损失函数。

---
- [扩散模型入门（七）](#扩散模型入门七)
  - [扩散过程及其概率密度表示](#扩散过程及其概率密度表示)
  - [训练目标的交叉熵解析式 $L$](#训练目标的交叉熵解析式-l)
  - [目标函数的化简一：化简扩散终点](#目标函数的化简一化简扩散终点)
  - [目标函数的化简二：化简边缘分布 $x\_0$](#目标函数的化简二化简边缘分布-x_0)
  - [目标函数的化简三：化为条件概率](#目标函数的化简三化为条件概率)
  - [目标函数的化简四：进一步整理](#目标函数的化简四进一步整理)
  - [附录：引理 1 的证明，推断终点的解析式 $p(x^0)$](#附录引理-1-的证明推断终点的解析式-px0)
  - [附录：一种好玩的积分表示方法](#附录一种好玩的积分表示方法)


## 扩散过程及其概率密度表示

在整个扩散过程中，其概率密度函数的变化过程可以表示成如下形式

$$
\begin{cases}
\pi(y) &= \int dy' \cdot T_\pi(y \mid y'; \beta) \pi(y') \\
q(x^{t} \mid x^{t-1}) &= T_\pi(x^t \mid x^{t-1}; \beta_t)
\end{cases}
$$

其中，$\pi, q$ 分别代表信号的自然分布和扩散过程的条件分布。整个 $0 \rightarrow T$ 的扩散过程可以表示为条件概率密度函数的连乘

$$
q(x^{0\cdots T}) = q(x^0) \prod_{t=1}^{T} q(x^t \mid x^{t-1})
$$

其中，$q(x^0) = \pi(x^0)$ 是原始信号的“自然分布”。而扩散模型要求解其逆过程

$$
\begin{cases}
p(x^T) &= \pi(x^T) \\
p(x^{T \cdots 0}) &= p(x^T) \prod_{t=1}^{T} p(x^{t-1} \mid x^t)
\end{cases}
$$

因此，扩散模型的推断过程终点可以表示为

$$
p(x^0) = \int dx^{T \cdots 1} \cdot p(x^{T \cdots 0})
$$

## 训练目标的交叉熵解析式 $L$

扩散模型的训练目标是寻找合适的 $p$ 使其从噪声中推断出信号 $x^0$ 的概率最大，因此考虑 $p, q$ 的交叉熵

$$
L = \int dx^0 \cdot q(x^0) \cdot \log p(x^0)
$$

扩散终点的解析式如下（引理1）

$$
p(x^0) = \int dx^{1 \cdots T} \cdot q(x^{1 \cdots T} \mid x^0) \cdot p(x^T) \prod_{t=1}^{T}
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})}
$$

由于上式满足 convex transformation 性质，因此利用 jensen's inequality 不等式有

$$
\log p(x^0) = \log \int dx^{1 \cdots T} \cdot q(x^{1 \cdots T} \mid x^0) f(p, q, x) \ge
\int dx^{1 \cdots T} \cdot q(x^{1 \cdots T} \mid x^0) \cdot \log(f(p, q, x))
$$

代入原式有

$$
L \ge K:=
\int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot \log \left( p(x^T) \prod_{t=1}^{T}
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})} \right)
$$

因此，$K$式就是我们的目标函数

$$
\hat{p} = \argmax_p K_p
$$

[Jensen&#039;s inequality](https://en.wikipedia.org/wiki/Jensen's_inequality)

## 目标函数的化简一：化简扩散终点

利用对数性质进行改写如下

$$
K = \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot \left( \log p(x^T) + \sum_{t=1}^{T} \log
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})} \right)
$$

考虑第一项

$$
K_1 = \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot  \log p(x^T) =
\int d x^{T} \cdot q(x^{T}) \cdot  \log p(x^T) = - H_p(x^T)
$$

其中，$H_p(x^T)$代表扩散终点的交叉熵，这样做的原理是扩散终点是服从标准正态分布的多维高斯噪声，它与扩散的过程无关。

## 目标函数的化简二：化简边缘分布 $x_0$

由于信号本身具有特定的分布，因此需要将其一般化，需要考虑的数字特征是 $t=0, 1$ 时的情况，有等式如下

$$
p(x^0, x^1) = q(x^0, x^1) \rightarrow
\pi(x^1) p(x^0 \mid x^1) = \pi(x^0) q(x^1 \mid x^0)
$$

进一步将 $K$ 式化简为

$$
K = K_1 + \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot \left(
\log \frac{p(x^0 | x^1)}{q(x^1 | x^0)} +
\sum_{t=2}^{T} \log
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})} \right)
$$

考虑中间项

$$
K_2 = \int d x^{0 \cdots 1} \cdot q(x^{0 \cdots 1}) \cdot \left(
\log \frac{p(x^0 | x^1)}{q(x^1 | x^0)} \right) =\\ \int dx^0 \cdot q(x^0) \log \pi(x^0) - \int dx^1 \cdot q(x^1) \log \pi(x^1) = 0
$$

这是由于在扩散过程中下式总为常数，因此$K_2 = 0$

$$
\int dx \cdot q(x) \log \pi(x) = -H_p(x)
$$

事实上，这一步的简化比较牵强，笔者更倾向于认为这一项是消除了 $x_0$ 的影响，这个影响并非消失了，而是以条件概率的形式继续存在于 $K_3$ 项中。

## 目标函数的化简三：化为条件概率

由于扩散过程的起点是 $x_0$ ，因此将 $q$ 化为条件概率

$$
q(x^t \mid x^{t-1}) = q(x^t \mid x^{t-1}, x^0)
$$

由贝叶斯原理可知，下式恒成立

$$
q(x^t \mid x^{t-1}, x^0) \cdot q(x^{t-1} \mid x^0) = 
q(x^{t-1} \mid x^{t}, x^0) \cdot q(x^{t} \mid x^0) 
$$

令

$$
K_3 = \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot
\sum_{t=2}^{T} \log
\left(
\frac{p(x^{t-1} \mid x^{t})}
{q(x^{t-1} \mid x^{t}, x^0)}
\cdot
\frac{q(x^{t-1} \mid x^0)}{q(x^t \mid x^0)}
\right)
$$

将其代入原式，得

$$
K = K_1 + K_3
$$

## 目标函数的化简四：进一步整理

进一步整理得

$$
K_3 = K_{31} + K_{32}
$$

其中

$$
K_{32} = \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot
\sum_{t=2}^{T} \log
\left(

\frac{q(x^{t-1} \mid x^0)}{q(x^t \mid x^0)}
\right)
$$

可以进一步化简为

$$
K_{32} = \sum_{t=2}^{T} \left(
H_q(x^t \mid x^0) - H_q(x^{t-1} \mid x^0)
\right) = H_q(x^T \mid x^0) - H_q(x^1 \mid x^0)
$$

另外

$$
K_{31} = \int d x^{0 \cdots T} \cdot q(x^{0 \cdots T}) \cdot
\sum_{t=2}^{T} \log
\left(
\frac{p(x^{t-1} \mid x^{t})}
{q(x^{t-1} \mid x^{t}, x^0)}
\right)
$$

经整理得

$$
K_{31} = - \sum_{t=2}^{T} \int dx^0 dx^t \cdot q(x^0) q(x^t) D_{KL}\left(
q(x^{t-1} \mid x^t, x^0) \mid \mid p(x^{t-1} \mid x^t)
\right)
$$

最终

$$
K = K_{31} + H_q(x^T \mid x^0) - H_q(x^1 \mid x^0) - H_p(x^T)
$$

$\blacksquare$

## 附录：引理 1 的证明，推断终点的解析式 $p(x^0)$

题设：

$$
p(x^0) = \int dx^{1 \cdots T} \cdot q(x^{1 \cdots T} \mid x^0) \cdot p(x^T) \prod_{t=1}^{T}
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})}
$$

证明：

$$
p(x^0) = \int dx^{T \cdots 1} \cdot p(x^{T \cdots 0})
\frac{q(x^{1 \cdots T} \mid x^0)}{q(x^{1 \cdots T}\mid x^0)}
$$

由于积分变量是联合分布，因此可以任意更改其顺序，有如下等式成立

$$
\begin{cases}
dx^{i \cdots j} &= dx^{j \cdots i} \\
q(x^{1 \cdots T} \mid x^0) \cdot q(x^0) &= q(x^{0 \cdots T})
\end{cases}
$$

代入原式有

$$
p(x^0) = \int dx^{1 \cdots T} \cdot q(x^{1 \cdots T} \mid x^0) \cdot p(x^T) \prod_{t=1}^{T}
\frac{p(x^{t-1} \mid x^{t})}{q(x^t \mid x^{t-1})}
$$

$\blacksquare$

## 附录：一种好玩的积分表示方法

本文借用 Deep Unsupervised Learning using Nonequilibrium Thermodynamics 一文的积分表示方法，它似乎在表达积分变量和被积函数方面具有优势，它避免了被积函数过长而导致积分变量过于靠后的问题

$$
\int f(x) dx \rightarrow \int dx \cdot f(x)
$$

$\blacksquare$