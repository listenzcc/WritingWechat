## 图解贝斯公式

本文对贝叶斯公式进行图解。
并且说明，在先验知识存在的情况下，观测样本只能在一定范围内对后验概率进行修正。
而不是直接进行数据驱动地估计。
这即是贝叶斯公式背后的精湛哲学。

---
- [图解贝斯公式](#图解贝斯公式)
- [贝叶斯公式原理图解](#贝叶斯公式原理图解)
  - [简要说明](#简要说明)
  - [概率修正](#概率修正)

## 贝叶斯公式原理图解

![图解贝叶斯公式.png](图解贝叶斯公式.png)

### 简要说明

图上半部分属于

> 我比教材聪明系列

因为多数教材和简谱文只用类似中间的图，就试图说明“复杂”的贝叶斯公式。
在我看来，凡是使用单一平面的尝试，皆是不可能的。
因为这样无疑会混淆

$$ P(B|A) $$

和

$$ P(BA) $$

两种截然不同情况。

而事实上，条件概率，与联合概率不同，$P(B|A)$是在$A$的概率空间中，看到$B$发现的概率。
而联合概率是在“全概率空间”内，看到$A$和$B$同时发生的概率。
二者之不同，导致它们无法表示在同一空间内。

经过上述澄pi清ping，相信你可以看明白三张图的用意，在此不多废话。

### 概率修正

下面是一则经典的例子。

> 如何使用贝叶斯公式进行概率“修正”，而不是估计。

例子可以参考[诊断试验中的贝叶斯定理：检验阳性就一定患病了吗？](https://zhuanlan.zhihu.com/p/31149473 "诊断试验中的贝叶斯定理：检验阳性就一定患病了吗？")。

模拟过程使用`python`代码，可以参考我的[GITHUB仓库](https://github.com/listenzcc/JupyterScripts.git "GITHUB仓库")。
代码如下


- 引用的包
```python
import numpy as np
import plotly.express as px
```

- 计算后验概率的函数

```python
def compute_PA_B(PA, PB_A):
    PnA = 1 - PA
    PB_nA = 1 - PB_A

    num = PB_A * PA
    den = PB_A * PA + PB_nA * PnA

    return num / den
```

- 在参数组合下修正后验概率的方法

```python
PA_B = []
PB_A_list = [0.7, 0.8, 0.9]
PA_list = [0.01, 0.1, 0.2, 0.5, 0.8, 0.9]
for PB_A in PB_A_list:
    PA_B.append([])
    for PA in PA_list:
        tmp = compute_PA_B(PA, PB_A)
        PA_B[-1].append(tmp)

PA_B
```

- 画图的方法

```python
fig = px.imshow(PA_B, title='Bayesian Estimation')
fig.update_layout(dict(
    xaxis=dict(
        tickvals = [e for e in range(len(PA_list))],
        ticktext = PA_list,
        title='P(A)'
    ),
    yaxis=dict(
        tickvals = [e for e in range(len(PB_A_list))],
        ticktext = PB_A_list,
        title='P(B|A)'
    ),
))
fig.show()
```

阅读愉快。