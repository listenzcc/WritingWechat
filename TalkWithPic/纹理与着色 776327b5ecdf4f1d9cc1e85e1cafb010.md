## 纹理与着色

如果你喜欢某一张图的配色，想把颜色方案应用到另一张图上。本文提供的方法和代码可以帮你一把。

---
- [纹理与着色](#纹理与着色)
- [CNN 模型](#cnn-模型)
  - [更多的结果](#更多的结果)
- [How to use](#how-to-use)
- [Contents](#contents)

## CNN 模型

CNN是个很好用的东西，在图像处理领域，它对纹理的识别和分析尤其有效。那么我们就充分利用它的纹理特性，建立这样的对应关系

$$ rgb = \psi(texture) $$

其中，$rgb$代表三个颜色通道，$texture$代表局部纹理特征。

当然，为了让它可计算，我们定义

$$ rgb \in R^{3} $$

以及

$$ texture \in R^{w \times h} $$

为了更确切地说明这两个东西的关系，可见示意图如下

![Texture & RGB](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/texture-rgb.png)

Texture & RGB

为了简单起见，我使用了一个特别简单的网络结构，如下图所示。

![CNN-Model](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/CNN.png)

CNN-Model

为什么用这么个网络结构呢？它优于其他结构吗？我也不知道。因为参数是随便写的，它的规模不算很大，loss 能降得足够低，似乎也不耽误使用，再加上我也懒得调了。所以就这样吧。

整个计算过程也并不复杂，

- 首先将彩色图像的颜色信息消除，得到灰度图像；之后对灰度图像进行随机取样，取样的窗口大小设置为 14 个像素宽和 14 个像素高，这就是 texture。
- 在训练阶段，我们当然是知道某一个窗口中心的颜色值的，这个 RGB 颜色值就是网络的输出。
- 对于任意一张图来讲，我们都能随机采样得到大量的小窗口，也就是说我们能够拿到足够多的训练样本。
- 在训练完成后，对于新的图像，我们就总能够根据它的灰度纹理图，通过网络计算出每一个像素的颜色 RGB 值，即对它进行重新着色。

![Picture-compare](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/compare.png)

Picture-compare

重新着色的样例如下，上面两张是原图，下面两张是重新着色的图

![3.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/3.jpg.jpg)

![1.jpg.3.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/1.jpg.3.jpg.jpg)

![1.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/1.jpg.jpg)

![3.jpg.1.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/3.jpg.1.jpg.jpg)

效果还是看得过去的，尤其是没有破坏原有的纹理结构，似乎还稍微加强了一点。

当然，这么麻烦肯定不是为了某一张图，而是可以批量地做一系列图像。下面矩阵中的最后一列为原始图像，左侧 5 列分别为重新着色后的图像。

有点稍息、立正和向右看齐的感觉。

![Color-results](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/results.png)

Color-results

### 更多的结果

或者你觉得上面的图太“同质”化了，于是我又加了两张“风景”图进去。模型好像认为大块的渐变纹理应该是绿色，所以星星和右下角的亮面就都绿了，这就很人工智障。

虽然染色过程没有什么问题，但由于两张图的色调不怎么搭，所以染上去的效果比较奇怪。看来还是不能过于信任机器。

![6.png.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/6.png.jpg)

![1.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/1.jpg.jpg)

![5.jpg.1.jpg.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/5.jpg.1.jpg.jpg)

![1.jpg.6.png.jpg](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/1.jpg.6.png.jpg)

![Untitled](%E7%BA%B9%E7%90%86%E4%B8%8E%E7%9D%80%E8%89%B2%20776327b5ecdf4f1d9cc1e85e1cafb010/Untitled.png)

本文的代码可见我的 github 仓库。


[Github](https://github.com/listenzcc/color-texture "Github")

图像素材是从一个绘画博主那里下载的。


[咬人画的](https://card.weibo.com/article/m/show/id/2309404764658962923595 "咬人画的")

以下内容是如何使用这个工具，以及工具里都包含什么内容，想必大家也并不关心。我就直接把 readme 照搬过来了。

## How to use

The main.py is all you need for a quick startup.

```bash

# The example of train the CNN model using 1.jpg as example
# The model will be trained,
# the parameters will be saved,
# and the other pictures will be converted.

python main.py assets/1.jpg

```

## Contents

The project contains the folders:

- assets: The pictures being converted with each other;
- converted: The converted pictures;
- parameters: The trained parameters of the pictures in assets.

The project contains the scripts:

- images.py: The python script to load image into Image class;
- main.py: The main python script of training the model, it also converts the pictures;
- batch.sh: The shell script of running several main.py.

The parameters of the CNN:

- The parameters are specifically to the picture;
- After the model is trained, the parameters will be saved in the parameters folder for future usage.