## 线性模型的实例之一

线性模型是解析观测变量的有效手段。
但它实在是太庞大了，所以只能蚂蚁式的、慢慢地啃下来。

---
- [线性模型的实例之一](#线性模型的实例之一)
- [一个实例](#一个实例)
- [线性模型](#线性模型)
  - [线性回归方程](#线性回归方程)
  - [统计检验](#统计检验)

## 一个实例

我们如何确定大脑中的哪些神经元响应哪些响应？
很简单，给它不同的刺激，看哪种刺激响应更强就可以了。

![Brain-1](Brain-1.png)

上图展示了几个脑区内的神经响应程度的估计，
其中，蓝、白色的部分用于勾画轮廓；
红、绿色标示了哪些神经元响应特定的任务。

怎么得到的呢？
是通过线性模型算出来的。

## 线性模型

先说句大话，

> 线性模型就是将我们看到的世界用代数的方法表达出来，
> 并且给出数值上的解释。

有点绕，我们分开来看，

- 什么叫代数呢？

  简单来说就是用数的方法来表达，
  比如身高、体重、收入等物理量，
  甚至还比如爱好、认知等可以通过数值来度量的量。

- 什么叫数值上的解释呢？

  就是同样用代数化的方法将影响它们的因素进行量化，
  进而建立**线性模型**，
  对这些因素的贡献程度进行估计。

这就对应着一些显而易见的、合乎常理的、符合逻辑的推断，
比如，

$$身高 \rightarrow 母亲身高，父亲身高，摄入蛋白，锻炼量，\dots$$

$$收入 \rightarrow 宗教信仰，受教育程度，年龄，智商，\dots$$

其中，箭头左边一般是我们观测到的“**因变量**”；
箭头右边一般是我们想确定其贡献的“**自变量**”。
线性模型就是通过代数方法，
帮助我们确定“因变量”受到哪些“自变量”的影响；
以及这些“自变量”的贡献是大是小。
这一工作，一般是使用线性回归方程来完成。

### 线性回归方程

当我们得到了一组观测值，
当然可以使用实向量来表示它

$$y \in R^n$$

其中，$n$表示样本数量。

为了对观测值进行解释，
我们需要选定一些“自变量”，
也用向量的形式来表示

$$X \in R^{n \times m}$$

其中，$m$为自变量数量。

此时，构造线性回归方程

$$y = X \cdot \beta + \varepsilon$$

其中，$\beta \in R^m$是回归系数，$\varepsilon \sim \mathbb{N}(0, \delta^2)$代表服从白噪声分布的回归残差。

这个方程的解法有一个非常简单的版本

$$\hat{\beta} = \argmin_{\beta} || y-X\beta ||_2^2$$

其中，$|| \cdot ||_2^2$代表二范数。
此时，我们可以将$y$表示为$X$因素的线性组合

$$y = \sum_{i=1}^{m} X_i \cdot \beta_i + \varepsilon$$

可见，$\beta_i$可以表征该自变量（特征）对观测值的贡献大小。

似乎我们解决了刚刚提出的问题，即对自变量（特征）的重要进行了度量。
接下来的问题，就是我们是否能信任我们求得的数值呢？
这就需要使用统计检验方法来帮忙。

### 统计检验

简单来说，

> 统计检验方法就是告诉我们,
> 某一次实验的结果，
> 有多大可能性在之后的实验中还能够复现的方法。

它还有一个名字，叫做假设检验，

> 我们假设一种平凡的情况，
> 然后求得在平凡情况下，出现我们观测到的值的概率，
> 若这个概率特别小，我们就能否定一开始的平凡假设。

有点悲伤，是吧？
因为我们永远无法知道事实，只能通过经验合理地封存我们的怀疑。
这正应了西方哲学史上很著名的那句话

> 唯有怀疑不可怀疑。

回到正题，
当我们求解了线性回归方程，
如何对求得的$\beta$值进行检验呢？
检验的结果能够告诉我们什么呢？

我们一般假定，某个因素对观测其实没有贡献，即

$$Null-hypothesis: \beta_i \cdot X_i = 0$$

而由于一般来说，
我们要求特征矩阵$X$中的各个列之间线性无关，
因此，我们的$\beta_i$值越大，平凡假设就越不可能为真。

其中的数值计算方法可以稳步我以前的发布（[统计检验](http://mp.weixin.qq.com/s?__biz=MzkxNTI1MDc5NA==&mid=2247483981&idx=1&sn=73c9b4e79e01de73cf08a4bfda07452b&chksm=c1634948f614c05e95b0011231f987016ffea0c1b815642e86d782e4a75e1e33b6ae84fa0d46&token=316307349&lang=zh_CN#rd "统计检验")，[显著性](http://mp.weixin.qq.com/s?__biz=MzkxNTI1MDc5NA==&mid=2247483985&idx=1&sn=bf5d515c9d78022ce82561f395837456&chksm=c1634954f614c042094b8c9ea1363fa9047d3c764e963cd37c504479efdf0fda97bf7d9ff4be&token=316307349&lang=zh_CN#rd "显著性")）。

简单来说，我们假设这些$\beta$值服从特定的分布，正态分布、泊松分布、T分布等等。
只要我们发现观测到的$\beta$值在给定分布中出现的概率小于特定值，一般取概率值$*p<0.05$，
那么我们就可以说，这个因素确确实实是影响我们观测值的重要因素。