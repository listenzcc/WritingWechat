## 从检验到瞎编

本文将正式介绍统计检验的基本方法，并简要说明它的适用范围，以及它是怎么被玩坏的。

---
- [从检验到瞎编](#从检验到瞎编)
- [统计检验](#统计检验)
  - [保守的空假设](#保守的空假设)
  - [渣男的两难](#渣男的两难)
- [多重比较及其校正](#多重比较及其校正)
  - [多重比较](#多重比较)
  - [多重比较校正](#多重比较校正)


## 统计检验

### 保守的空假设

统计检验是常见的统计学方法。
它可以用来对统计量背后的客观情况进行定性。
为了简单起见，我们本篇文章只讨论正态分布随机变量的统计检验问题

$$ X \sim \mathcal{N}(\mu, \delta^2) $$

在此假设下，我们一般关心这样一种情况，即观测到的样本，其总体分布的均值$\mu$是否大于零。

在选择公理的支配下，这样的判断明显对应着两种基本判断之一

- 真实均值等于零；
- 真实均值不等于零。

而由于两种判断的互斥特性，我们可以专注于相当保守的判断，即

- 真实均值等于零。

一般情况下，我们把这个“**保守**”的判断，称为“原假设”、“零假设”或“空假设”（[Null Hypothesis](https://mathworld.wolfram.com/NullHypothesis.html "Null Hypothesis")）。
在统计分析中，我们约定俗成地认为，空假设一般都对应着这种“保守”的假设。

### 渣男的两难

而本着“不主动、不负责”的渣男精神，当我们给出一个判断的时候，都面临着两种可能的错误，即[两类错误](https://web.ma.utexas.edu/users/mks/statmistakes/errortypes.html#:~:text=Type%20I%20and%20II%20Errors%20and%20Significance%20Levels,Correct%20Decision%20%20%20Type%20II%20Error%20 "两类错误")。

- 第一类错误，错误地拒绝了空假设的错误；
- 第二类错误，错误地接受了空假设的错误；
- 两类错误的解释如下表所示

|            | Truth 0       | Truth 1       |
| ---------- | ------------- | ------------- |
| Decision 1 | Type I Error  | True Positive |
| Decision 0 | True Negative | Type II Error |

从表格中可以看到，当空假设其实不成立，而我们却错误地认为它成立时，属于第一类错误，或称为“采伪错误”；反之，当空假设其实成立，但我们却错误地认为它不成立时，属于第二类错误，或称为“弃真错误”。

暂且不论真实情况如何，单纯从表中的排布来看，
我们得出拒绝空假设的结论时，面临第一类错误；
而我们得出不拒绝空假设的结论时，面临第二类错误。
因此，二种错误是此消彼涨的关系。
也就是说，渣男不好当。

而本着“宁可放过，不可错杀”的严谨态度，我们往往更加关注“第一类错误”。
即，只有我们有充分证据的情况下，才能合理拒绝空假设。
这样，我们拒绝空假设的风险才能始终是足够小的。
在统计学上，我们一般将这种可以容忍的错误上限，记为$\alpha$，实践上，一般取$\alpha=0.05$。
代表，我们以置信度大于$95\%$的概率，认为空假设是不合理的，从而拒绝它。

以上，即是$5\%$显著性水平的由来。

## 多重比较及其校正

### 多重比较
当然，以上推导并不说，只要找到了满足$\alpha$阈限要求的证据，我们就能合理地拒绝空假设呢？
答案十分的模棱两可：

> 是，但不完全是。

我们这里考虑一种特殊的，多重比较问题。

假设这样一种情况，我们有$n$个样本。
当然，它们的取值服从正态分布，但均值和方差未知。
其中，“平凡”或“普通”样本的值为零，“目标”样本的值非零。
而我们的目的，就是确定其中是否有非零样本，并找到这些非零样本。

从前面文章的分析可以看到，我们可能通过下式，对样本的取值进行Z分数变换

$$ Z = \frac{X - \hat{\mu}}{\hat{\delta}} $$

其中，$\hat{\mu}$和$\hat{\delta}$分别代表均值和标准差的“[无偏估计](https://encyclopediaofmath.org/wiki/Asymptotically-unbiased_estimator "无偏估计")”。
这样，$n$个样本的$Z$值满足正态分布。

这样就很尴尬，因为这些样本中几乎一定有满足$\alpha$阈值要求的样本。
那么，我们能说这些样本就是我们要找的“非平凡”样本吗？

> 是，但不完全是。

因为，我们此时并不是进行了一次判断，而是进行了$n$次判断。
而这$n$次判断是一个整体，因为其中少了任意一个，Z分数变换都不能成立。
为了避免$n$次判断造成的影响，我们就需要进行多重比较校正。

### 多重比较校正

为了对多重比较带来的误差进行校正，我们需要对多重比较带来的误差进行估计（废话）。
由联合概率的计算方法可得，若我们进行了$n$次比较，且每次比较发生错误的概率都是$\alpha$，则有

$$ \Alpha_n = 1 - (1-\alpha)^n $$

其中，$\Alpha_n$代表$n$次判断的情况下，出错的概率。

那么为了对多重比较进行校正，我们需要对$\Alpha_n$进行约束，而新$\hat\alpha$则应满足下式

$$ \hat\alpha = 1 - (1 - \Alpha_n)^{1/n} $$

在$\Alpha_n$为$0.05$的情况下，$\hat\alpha$的值如下表所示

|  $n$  | $\hat\alpha$ |
| :---: | :----------: |
|   1   |    0.0500    |
|   2   |    0.0253    |
|   3   |    0.0170    |
|   4   |    0.0127    |
|   5   |    0.0102    |
|   6   |    0.0085    |
|   7   |    0.0073    |
|   8   |    0.0064    |
|   9   |    0.0057    |

可见，随着$n$次数的增加，所需要的$\hat\alpha$值同样极速下降。
也就是说，随着比较次数的增加，我们需要同步缩紧拒绝空假设的阈值，才能有效避免第一类错误。
顺便提一句，这种校正方法称为[Family-Wise Error Rate]( https://www.sciencedirect.com/topics/mathematics/familywise-error-rate "Family-Wise Error Rate")校正，属于最严格的校正方法。

由于如此严格的方法，几乎拒绝了一切狡辩的可能。
从而使得几乎很少有多重比较的情况能通过这种检验，所以“人至察则无徒”，在真实环境中很少使用。

在下一篇文章中，我将介绍人性化得多的校验方法，从而放大家一条生路。











