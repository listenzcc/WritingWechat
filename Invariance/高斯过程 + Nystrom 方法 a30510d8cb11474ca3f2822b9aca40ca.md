# 高斯过程 + Nystrom 方法

由于高斯过程可以用于建模连续无限维空间中的函数,而 Nystrom 方法可以用于在有限维度空间中近似计算高斯过程, 因此将两者结合可以有效地解决大规模机器学习中的核方法问题。
高斯过程的求解关键在于核函数，而 Nystrom 方法则说明了这样一个事实，那就是在观测空间的随机采样对核函数估计的准确性影响有限。于是本文对这个原理提供一个可交互的可视化平台。

[Gaussian Process with ChartJS Interactive](https://observablehq.com/@listenzcc/gaussian-process-with-chartjs-interactive)

---
- [高斯过程 + Nystrom 方法](#高斯过程--nystrom-方法)
  - [方法原理](#方法原理)
  - [随机采样的不变性](#随机采样的不变性)
  - [附录：高斯过程](#附录高斯过程)
  - [附录：Nystrom 方法](#附录nystrom-方法)


## 方法原理

具体来说,Nystrom 方法通过采样训练数据子集来近似核函数矩阵,从而减小计算量并实现核方法在大数据集上的可扩展性。而高斯过程则为 Nystrom 方法提供了更为强大的建模能力,即利用核函数在输入空间中建立复杂的概率分布,实现更为精细和灵活的函数建模。因此,高斯过程 + Nystrom 方法可以看作是一种更为高级和实用的核方法,在大规模数据集建模中发挥了重要作用。

从附录中的计算原理可见，高高斯过程的求解关键在于核函数，而 Nystrom 方法则说明了这样一个事实，那就是在观测空间的随机采样对核函数估计的准确性影响有限。于是本文对这个原理提供一个可交互的可视化平台。下图中的红色点代表观测值，绿色线代表估计出的均值曲线，灰色区域代表局部方差。并且实验结果说明观测点越多，则方差（即估计的不确定性）就越小。这是既符合直觉也符合推导的结果。

![Untitled](%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%20+%20Nystrom%20%E6%96%B9%E6%B3%95%20a30510d8cb11474ca3f2822b9aca40ca/Untitled.png)

![Untitled](%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%20+%20Nystrom%20%E6%96%B9%E6%B3%95%20a30510d8cb11474ca3f2822b9aca40ca/Untitled%201.png)

## 随机采样的不变性

接下来我们来验证在观测空间的随机采样对核函数估计的准确性影响有限这一观点。由于随机采样这个事情相当于是在时间上的动态效果，因此请允许我用一段视频来呈现它。通过点击 Random select 按钮，我们模拟在“均值曲线”上对样本进行重新采样的效果。从视频中可以看到，虽然观测样本的位置发生了变化，但重新估计后的均值曲线并没有较大的变化。这个结果验证了随机采样对核函数估计较小的假设。

【一段棒到不行的视频】

---

## 附录：高斯过程

面对一个服从高斯分布的随机变量，如果它的维度之间不相互独立，我们总能用多元高斯分布来描述它

$$
X \sim \mathcal{N}(\mu, \Sigma^2)
$$

这时考虑随机过程满足确定但未知的函数关系，原函数及其抽样可以表示成下式

$$
\begin{cases}
y=f(x)\\
y^* = f(x^*)
\end{cases}
$$

由于抽样值是观测到的，可以进行数值计算的成对数据，因此我们的目的是采用数据驱动的方法对原函数进行估计。为了计算起见，我们使用核函数的方法对协方差矩阵进行近似

$$
\mathcal{K}(x_1, x_2) = s^2 \cdot \exp(\frac{\Vert{x_1-x_2}\Vert^2}{2l^2})
$$

其中，$x_1, x_2$代表两个随机变量，$s,l$代表两个超验参数。因此观测样本的随机变量满足下式。从下式中可以看到核函数的优势是能够建立原函数自变量与因变量之间的关系。

$$
y^* \sim \mathcal{N}(\mu_{y^*}, \Sigma_{y^*y^*}) = 
\mathcal{N}(\mu_{y^*}, \mathcal{K}_{x^*x^*})
$$

推而广之，原函数满足如下分布

$$
f(x) \sim \mathcal{N}(\mu_f, \hat{\Sigma}_{ff}) =
\mathcal{N}(\mu_f, \mathcal{K}_{xx})
$$

将以上两式联立可得方程组形式的联合分布

$$
\begin{bmatrix}
f(x)\\
y^*
\end{bmatrix} = 
\mathcal{N}(
\begin{bmatrix}
\mu_f\\
\mu_{y^*}
\end{bmatrix},
\begin{bmatrix}
\begin{array}{l}
\mathcal{K}_{ff} & \mathcal{K}_{fy^*}\\
\mathcal{K}_{y^*f} & \mathcal{K}_{y^*y^*}
\end{array}
\end{bmatrix} 
)
$$

利用 EM 算法联立方程，可得解析解如下

$$
f(x) \sim \mathcal{N}(
\mathcal{K}^T_{ff} \mathcal{K}^{-1}_{ff} y^* + \mu_f,
\mathcal{K}_{y^*y^*} - \mathcal{K}^T_{fy^*} \mathcal{K}^{-1}_{ff} \mathcal{K}_{fy^*}
)
$$

## 附录：Nystrom 方法

Nystrom 方法的核心，即低秩表示的原理进行解释。有了矩阵分解式打底，我们可以将核函数矩阵表示为简单形式

$$
K = U \cdot \Lambda \cdot U^T
$$

从上式可知，此矩阵的秩完全由对角矩阵$\Lambda$控制。所谓低秩表示，即是认为该矩阵对角线上的元素从大到小进行排列，这个有序数列呈现快速收敛到 $0$ 的特性。因此，我们总可以使用前若干个特征值对它进行降维表示而不影响核函数的精度。

$$
\tilde{K} = \tilde{U} \tilde{\Lambda} \tilde{U^T}
$$

其中，$\tilde{\cdot}$代表选择其中的低秩成分

$$
K_{nm} = U_{nm} \Lambda_{mm}U_{nm}^T
$$

其中，$n$和$m$分别代表样本数量和低秩成分的数量。