# Invariance

There are several invariance by math.
Knowing them means knowing everything.

---
## 一些不变性（之一）

函数的本质是映射。
而“不变性”是规范映射变量之间关系的重要渠道。
本文试图从不变性的角度，
探索描述惯性系之间坐标变换的“洛仑兹变换”。

## 一些不变性（之二）

之前提到双曲余弦函数，
它在复数空间内的性质十分有趣。

## 卷积及傅立叶变换的矩阵计算

傅氏变换与卷积都可以用矩阵乘法的形式进行表达。
图神经网络的优化正是以这种矩阵形式为基础的，
从信号连续空间到图拓扑空间的拓展。

本文是其中的第一步，
用矩阵的形式表达信号的傅氏变换与卷积。

本文只涉及必要的原理解释，
具体实现代码可见我的[GitHub 仓库](https://github.com/listenzcc/JupyterScripts.git "GitHub 仓库")。

## 卷积定理的矩阵巧合

从矩阵的角度来看“卷积定理”，
仿佛它只是数字角频率完备正交基下的一个特例。

## 有图必有谱

图的谱聚类

## 谱聚类

我们希望有这样一种算法，
它能够根据图中各个节点的连接度，
对它们进行分割。
这样，在对它们进行可视化的时候，
用户可以不再纠结把每个节点放在哪里，
而是可以通过一个简单的物理力学模拟，
达到放置在合适位置的效果。

【这是一段棒到不行的视频】

可以看到，
用户只需要做一些简单的拖拽，
就可以得到一张看得过去的可视化图结构。

### 图的矩阵表示

对于$N$个顶点构成的连接图，
总可以用$W \in R^{N \times N}$矩阵表示这些顶点之间的连接关系。
其中，$W_{ij}$代表节点$i, j$之间的连接强度。
此时，由于缺乏合适的定义方式，
该矩阵主对角线上的值均未定，
我们暂定它们为零。

为了补全矩阵对角上的值，
我们计算每个节点的“连接度”，
构造新的对角阵$A \in R^{N \times N}$

$$A_i = \sum_{j=1}^{N} W_{ij}$$

此时，我们可以通过$A$矩阵补全$W$矩阵，
从而构造“拉普拉斯”矩阵$L$

$$L = A - W$$

这个矩阵是谱聚类的基础。

### 指示向量

先不纠结物理意义，
我们直接构造一个指示向量$V_k \in R^N$

$$V_{ki} = x_i \in \{0, 1\}$$

这是一种比较绕的表示方法。
简单来说，
它是一个由$0$和$1$组成的$N$维列向量。

基于这个指示向量，
我们构造它的二次型

$$V_k^T \cdot L \cdot V_k$$

如果你熟悉矩阵的乘法规则，
可以容易看到二次型的值即是矩阵$L$相应行和列所有元素之和

![VtLV](VtLV.png)

它具有极其明确的物理意义，
代表按照指示向量$H_k$的要求对图进行切割之后，
所有不同组的节点之间的连接强度之和。

当我们对不同类的节点进行染色，
得到的效果如下图所示

![Cluster1](Cluster1.png)

图中的颜色代表不同组的节点，
图中的线条代表节点之间的连接。

### 谱聚类的原理

为了得到谱聚类的染色效果，
我们需要构造这样一个损失函数，
求解最优的指示向量$\hat{V}$，

$$\hat{V} = argmin_V (tr(V^T \cdot L \cdot V)) $$

其中，$tr(\cdot)$代表矩阵的迹。
从物理意义上讲，
它的意义是在切割边的连接度最小的情况下，
达到指示向量$V$所要求的切割目的。

而这显然是一个动态规划过程，
非常难以求解。
因此，我们转而寻求一个可行的解决方案，
它利用到一个简明的数学原理，即

> 实对称矩阵相似于对角阵

$$\Lambda = U^T \cdot L \cdot U$$

其中，$\Lambda$为对角矩阵，且$U$为对称矩阵

$$U^T \cdot U = I, U \cdot U^T = I $$

在$\Lambda$矩阵中，其对角线上的值为矩阵$L$的特征值。

因此，我们虽然不能直接求解损失函数，
但可以找到它的一个可行解的近似解，
只要选择最小的$k$个特征值，
它对应的$U_i, i \in \{N, N-1, \dots, N-k+1\}$个列就是目标指示向量的一组近似解。

### 聚类近似

但近似解无法直接当作指示向量来用，
因为它不满足元素非$0$即$1$的定义。

这里我们借用`K-Means`聚类的损失函数，
再为向量组$U_i$构造一组指示向量$H$，
使得其满足新的损失函数

$$\sum_{i=1}^k \sum_{u \in C_i} ||u-\mu_i||^2$$

其中，$\mu_i$代表第$i$个分割的几何中心。
同样借助二次型的计算方式，它等价于

$$argmin_{H} = tr(H^T \cdot U^T \cdot L' \cdot U \cdot H)$$

其中，$L'$的构造方式与拉普拉斯矩阵$L$非常相似，
$H$为`K-Means`的指示向量。

