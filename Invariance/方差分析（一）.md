## 方差分析（一）

本系列将逐步涉及方差分析的一些概念。
但在此之前，需要厘清一个更基本的问题，
为什么需要对数据进行方差分析。

---

- [方差分析（一）](#方差分析一)
- [线性模型](#线性模型)
- [简单实验](#简单实验)

## 线性模型

线性模型只规定了多个变量具有线性组合的计算关系，好像一个相当大的筐，什么都能往里装。

$$Y=\sum_{i} \alpha_i \cdot X_i + \sum_{j} \Beta_i \cdot X_j + \epsilon$$

为了避免问题过于复杂，首先考虑一种最简单的情形，
变量取值只有0、1两种，且不同变量相互正交。
即对于每个样本，它的所有自变量（因素）最多有且只有一个值取1，而其他值都是0。

$$股票价格=\alpha \cdot 员工是否加班 + \beta \cdot 员工是否摸鱼 + \gamma \cdot 今天是否是满月 + \psi \cdot 原材料是否能充足 + \epsilon$$

这时，各个自变量（因素）系数的意义是非常明确的，它代表该因素是否对因变量具有影响。
那么接下来的问题就是如何度量这种影响，是否存在，以及影响程度的大小。

最直觉的方式是通过样本的观测值求解线性模型，
对各个因素的系数进行统计检验，
通过判断它们是否为零达到分析影响程度的目的。

但很遗憾，这种方法几乎不可行。它至少面临两个问题，

- 首先，由于因素的取值1是出于归一化的目的任选的，所以无法对系数的分布进行先验规定；
- 其次，虽然可以通过样本统计量对分布进行强行估计，但这样做不可避免的涉及样本是如何进行划分的，导致得到的结果涉嫌循环论证，不具有统计效力；
- 进一步说，这涉及到任意划分方式之间比较的多重比较问题，统计效力随着所有可能的划分数量增加而迅速衰减，最终导致无法信任任何一种结果。

## 简单实验

这里需要举一个简单的例子，说明上述问题的存在性，
实验过程如下

- 首先生成服从标准正态分布的一组数据，数据包含`1000`个样本，它的直方图如下所示

  ![Raw](./anova-1-raw.png)

- 之后对数据进行随机分组，对其中一组的均值进行T检验，
  这个过程重复`1000`次，零假设为均值为零，检验结果的`p`值直方图如下所示

  ![Means](./anova-1-pvalue-means.png)

  数据呈现的结果非常有意思

  > 对标准正态分布进行随机分组，其中一半分组的均值的`p`值小于`0.05`


  这是一个相当“可怕”的结果，
  甚至可以说是统计科学家的“福音”。
  它说明对这组完全没有规律的数据，
  我们可以“指鹿为马”地任意指定一半样本为一类，
  那么这个完全没有道理的划分，
  有很大的概率能够得到与该类样本的均值与零值具有统计差异。

  这个荒谬的结果，
  直接堵死了我们通过仅对均值进行检验的方式，
  寻找数据规律的道路。

- 针对第三点，我们对两个组的均值进行检验，
  零假设为它们的均值相同，检验结果如下图所示

  ![Compares](./anova-1-pvalue-compares.png)

  这个结果虽然看上去稍微“正常”一些，
  （这里的“正常”是指`p`值小于`0.05`的检验数量“只是略高于”第一类错误的自然概率`0.05`）。
  但这种情况无助于解决多重比较问题，
  因为在多重比较的情况下，
  仅仅能够保证每一次比较的第一类错误发生概率为`0.05`是完全不够的。
  因为面对大数量的样本来说，所有可能的分割方法的数量也同样大，
  仅仅在`1000`次的随机分割检验下，就有`140`次假警发生，
  而实际的分割数量的数量级为$(1000, 500)$，远远大于这个数字

因此，我们需要找到另一种方法，
尝试解决这些问题。
这种方法应该能够针对“这种”划分，
对因素的系数是否不为零进行统计检验，
并且给出相应的概率水平。
这种方式就是方差分析。

方差分析是针对二阶统计量进行的统计分析，
它的理论基础非常简单，

> 就是数据样本数值的二阶统计量，
> 不随样本分割方式的不同而改变。

如下图所示

![Squares](./anova-1-squares.png)

图中以重叠的方式，绘制了随机分割条件下，
两类样本“方差”的直方图，
图中可以看到方差是一个不随分割变化的具有稳定性统计量。

此时，
一个直观的想法是，
它既然不随分割方式变化，那么它的变化受什么影响呢？