# 扩散模型-2

本文尝试将扩散过程反过来，即从随机噪声“生成”有意义的图像或者数据。

---

-   [扩散模型-2](#扩散模型-2)
    -   [损失函数与扩散链](#损失函数与扩散链)
    -   [反扩散的样例](#反扩散的样例)

## 损失函数与扩散链

所谓“有意义”的信号或图像是这样一组随机变量，它的取值服从特定的概率分布

$$
X_t \sim \Psi
$$

在该分布中的每一次采样就是对图像的生成。在扩散模型中，我们将该分布作为初始分布，将标准正态分布作为目标分布。在扩散模型中，我们假设它是一个链式反应

$$
X_t = f(X_{t-1})
$$

而它的简单版本为

$$
X_t = \sqrt{\bar{\alpha_t}} \cdot X_0 + \sqrt{1-\bar{\alpha_t}} \cdot \mathcal{Z}
$$

而在逆过程中，我们能够从服从标准正态分布的“噪声”出发，生成有意义的图像。达到这一目的的手段是将上面的链条反过来即可

$$
X_{t-1} = f^{-1}(X_t)
$$

但它不再有简单版本，因为我们没有正态分布进行训练。因此，我们得到损失函数如下。易见，该损失就是分布之间的 KL 散度。

$$
D_{KL}(\Psi, \Phi) = \mathbb{E}(log(\Psi) - log(\Phi))
$$

其中，$Y_t \sim \Phi$代表观测到数据的经验分布。在理想条件下它“应该”是我们所追求的“有意义”的分布

$$
\mathbb{E}(\Psi - \Phi) = 0
$$

## 反扩散的样例

本样例使用 Unet 作为扩散模型的基本算子，用于小步长迭代。在若干次迭代后，得到的终止值就是扩散结果。本例使用的目标图像如下

![Raw images](%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-2%20add96025499a4d788e654fe661c333d1/pic1.png)

Raw images

因为我手上的计算资源有限，因此用少量图像进行训练，可以得到如下的扩散结果。除了不太圆，看上去还挺好的。

![Generated images](%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-2%20add96025499a4d788e654fe661c333d1/pic2.png)

Generated images

以上单张图片的扩散过程如下

![pic3.png](%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B-2%20add96025499a4d788e654fe661c333d1/pic3.png)

该模型极其简单，它能够将大量白噪声图像映射到训练图像所在的概率空间中。因此，它的功能类似 VAE 的 decoder。而它的好处是不依赖于 VAE 的 encoder 就可以学习到“中间”层编码的逆变换结果，因此更适合大规模预训练。
