# 光场渲染的 MRI 点云

Nerf 是用深度神经网络表达某个物体，虽然我没有这个本事构造深度神经网络，但好在我并不需要这么做，因为我只要能根据已知的点云，把 MRI 数据渲染出来就达到目的了。本文开源代码可见我的在线代码笔记本

[3D MRI volume rendering in slices with WebGL](https://observablehq.com/@listenzcc/3d-mri-volume-rendering-in-slices-with-webgl)

---
- [光场渲染的 MRI 点云](#光场渲染的-mri-点云)
  - [光场渲染方法](#光场渲染方法)
  - [MRI 点云的渲染实例](#mri-点云的渲染实例)
  - [附录：实现方法](#附录实现方法)


## 光场渲染方法

前段时间 Nerf 的渲染方法在三维渲染领域引起了较大的关注，它的思想是用深度网络对三维物体的表面进行表达，它的实现方法是建立视角与物体表面之间的对应关系

$$
render = \phi(D, \theta)
$$

其中，$\theta$代表光线角度，$D$代表被摄物体的点云，$\phi$代表网络参数，它用来捕捉入射光线产生的渲染值，计算过程可以抽象成曲线积分

$$
v = \int_{far}^{near} D_s^\theta \cdot w_s  ds
$$

简单来说，积分过程就是想象一条从远处射来的光线，它“穿过”整个物体，携带着路径上的分部信息，最后进入观察者的眼睛。那么积分值就是观察者“看到”的物体。

[NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled.png)

## MRI 点云的渲染实例

Nerf 是用深度神经网络表达某个物体，虽然我没有这个本事构造深度神经网络，但好在我并不需要这么做，因为我只要能根据已知的点云，把 MRI 数据渲染出来就达到目的了。该方法既可以按分层的方法对感兴趣的 MRI 层进行渲染，也能够将整个大脑看作整体三维结构进行渲染。

- 层面渲染截图

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%201.png)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%202.png)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%203.png)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%204.png)

- 体透视渲染截图

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%205.png)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%206.png)

下面是录制的一小段操作视频，显示了本软件解决方案既可以从层面切片的形式进行渲染，也可以按体透视的方法进行渲染。

【视频占位】

## 附录：实现方法

需要说明的是，由于使用 Nerf 的思路进行渲染，因此这里看到的立体其实是在视角表面的“贴图”，只不过贴图是实时计算的，因此它们看上去“像是”真实的 3D 影像。

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%207.png)

![Untitled](%E5%85%89%E5%9C%BA%E6%B8%B2%E6%9F%93%E7%9A%84%20MRI%20%E7%82%B9%E4%BA%91%205e9d273bf6654cfe8f8528200cae14de/Untitled%208.png)

核心代码如下

```jsx
cube2 = {
  // Cube.
  const geometry = new THREE.BoxGeometry(1, 1, 1);

  // Brain.
  const material = new THREE.RawShaderMaterial({
    glslVersion: THREE.GLSL3,
    uniforms: {
      dataTexture: { value: volumeTexture2 },
      cameraPosition: { value: new THREE.Vector3() }
    },
    vertexShader: vertexShader.innerText,
    fragmentShader: fragmentShader2.innerText,
    side: THREE.BackSide,
    transparent: true
  });

  const cube = new THREE.Mesh(geometry, material);
  cube.scale.set(data.aspect[0], data.aspect[1], data.aspect[2]);

  // Cube outline.
  const line = new THREE.LineSegments(
    new THREE.EdgesGeometry(geometry),
    new THREE.LineBasicMaterial({ color: 0xeeeeee })
  );
  cube.add(line);

  return cube;
}
```