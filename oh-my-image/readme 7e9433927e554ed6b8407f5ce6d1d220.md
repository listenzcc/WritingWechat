## Intro

本文是一个工程尝试，一个针对图像操作的一站式自动服务项目。

---

-   [Intro](#intro)
-   [To-do list](#to-do-list)
-   [Load image](#load-image)
-   [Fit image](#fit-image)
-   [Label](#label)
-   [Depth](#depth)
-   [In-paint](#in-paint)
-   [Reconstruction](#reconstruction)

It is the demo showing what can be done to the image. Of course, with the help of the deep learning methods.

---

## To-do list

-   Loading image from everywhere;
-   Fit the image into well defined format;
-   Label the contains;
-   Image segmentation;
-   In-paint unwanted areas;
-   [n.a.] Reconstruct the 3D scene from the image.

---

## Load image

The dash app can do the collection job, [dash_app.py](./image-loader/dash_app.py). It establishes the front-end app that receives image, the users can drag their beloved image into the page from everywhere.

![drag](readme%207e9433927e554ed6b8407f5ce6d1d220/drag.png)

drag

The [my_image.py](./image-loader/my_image.py) receives the image and fit it into several versions. The images are saved in the folder in [image](./image) folder.

![raw](readme%207e9433927e554ed6b8407f5ce6d1d220/raw.jpg)

raw

## Fit image

The image will be re-size into fixed width for web usage. It will automatically create the thumbnail image for icon usage.

## Label

The [transformers](https://github.com/huggingface/transformers) module is used to label the contains of the image.

It segments the image as well.

The [analysis_transformers.py](./image-analysis/analysis_transformers.py) script runs over the [image](./image) folder, and analysis the images.

The objects in the image are detected, and the segmentation is performed to mask every possible objects.

-   Objects & Segmentation

![objects.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/objects.jpg)

![segment.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/segment.jpg)

-   Mask & Cover

![cover-8-person-0.97.png](readme%207e9433927e554ed6b8407f5ce6d1d220/cover-8-person-0.97.png)

![mask-8-person-0.97.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/mask-8-person-0.97.jpg)

## Depth

The [transformers](https://github.com/huggingface/transformers) also generate the depth map of the image.

![depth](readme%207e9433927e554ed6b8407f5ce6d1d220/depth.jpg)

depth

It seems that the transformers module works just fine.

## In-paint

The masks are used to in-paint the unwanted areas. The [generative_inpainting](https://github.com/JiahuiYu/generative_inpainting) module is used. However, the problem is the project is released in the tensorflow version of 1.x. So, I migrate it into the tensorflow version 2.x. The detail can be found in the doc of [tensorflow-1to2.md](./doc/tensorflow-1to2.md).

The [inpaint_generative.py](./image-inpaint/inpaint_generative.py) script runs over the [image](./image) folder, and inpaint the image with the masks.

-   Inpaint 1

![mask-8-person-0.97.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/mask-8-person-0.97%201.jpg)

![mask-8-person-0.97.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/mask-8-person-0.97%202.jpg)

-   Inpaint 2

![mask-3-person-0.99.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/mask-3-person-0.99.jpg)

![mask-3-person-0.99.jpg](readme%207e9433927e554ed6b8407f5ce6d1d220/mask-3-person-0.99%201.jpg)

It seems that the generative module works a little strange.

## Reconstruction

[N.A.]
